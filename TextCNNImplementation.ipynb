{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TextCNNImplementation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DaasDaham/Deep-Learning-NLP/blob/main/TextCNNImplementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zb8R--OeKRSb"
      },
      "source": [
        "text_corpus = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35lVTBSgMpz9"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchtext.legacy import data\n",
        "\n",
        "SEED = 1234\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchtext\n",
        "\n",
        "import nltk\n",
        "\n",
        "import random\n",
        "from sklearn.metrics import classification_report\n",
        "%matplotlib inline  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "d8XNHj2mNdgG",
        "outputId": "818bbbc3-2d91-495e-897e-197e8adf4509"
      },
      "source": [
        "import chardet\n",
        "chardet.detect(open('/content/Trec_Train_dataset.txt', 'rb').read())['encoding']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ISO-8859-1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 484
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcONtY-fMvn2"
      },
      "source": [
        "file1 = open('/content/Trec_Train_dataset.txt', 'r',encoding=\"ISO-8859-1\")\n",
        "Lines = file1.readlines()\n",
        "for line in Lines:\n",
        "    text_corpus.append(line.strip())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ih5GjJ1zin1G"
      },
      "source": [
        "import re\n",
        "labels = []\n",
        "for t in range(len(text_corpus)):\n",
        "    labels.append(text_corpus[t][:text_corpus[t].index(\":\")])\n",
        "    text_corpus[t] = text_corpus[t][text_corpus[t].index(\" \")+1:]\n",
        "    # text_corpus[t] = text_corpus[t].replace(\"'s\", \"\")\n",
        "    # text_corpus[t] = text_corpus[t].replace(\"'\", \"\")\n",
        "    # text_corpus[t] = text_corpus[t].replace(\"`\", \"\")\n",
        "    # text_corpus[t] = text_corpus[t].replace(\",\", \"\")\n",
        "    # text_corpus[t] = text_corpus[t].replace(\"!\", \"\")\n",
        "    # text_corpus[t] = text_corpus[t].replace(\".\", \"\")\n",
        "    # text_corpus[t] = text_corpus[t].replace(\":\", \"\")\n",
        "    # text_corpus[t] = text_corpus[t].replace(\"?\", \"\")\n",
        "    # text_corpus[t] = re.sub('[0-9]+s', '', text_corpus[t])\n",
        "    # text_corpus[t] = re.sub('[0-9]', '', text_corpus[t])\n",
        "    # text_corpus[t] = re.sub(' +', ' ', text_corpus[t])\n",
        "    text_corpus[t] = text_corpus[t].strip() \n",
        "text_corpus = pd.Series(text_corpus, name=\"Text\")\n",
        "labels = pd.Series(labels, name=\"Labels\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "JvTmkW_SQZ1l",
        "outputId": "7e3b871b-0e6a-46c1-8f07-19c7097bb881"
      },
      "source": [
        "df = pd.concat([text_corpus, labels], axis=1)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How did serfdom develop in and then leave Russ...</td>\n",
              "      <td>DESC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What films featured the character Popeye Doyle ?</td>\n",
              "      <td>ENTY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How can I find a list of celebrities ' real na...</td>\n",
              "      <td>DESC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What fowl grabs the spotlight after the Chines...</td>\n",
              "      <td>ENTY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the full form of .com ?</td>\n",
              "      <td>ABBR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5447</th>\n",
              "      <td>What 's the shape of a camel 's spine ?</td>\n",
              "      <td>ENTY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>What type of currency is used in China ?</td>\n",
              "      <td>ENTY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5449</th>\n",
              "      <td>What is the temperature today ?</td>\n",
              "      <td>NUM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5450</th>\n",
              "      <td>What is the temperature for cooking ?</td>\n",
              "      <td>NUM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5451</th>\n",
              "      <td>What currency is used in Australia ?</td>\n",
              "      <td>ENTY</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5452 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Text Labels\n",
              "0     How did serfdom develop in and then leave Russ...   DESC\n",
              "1      What films featured the character Popeye Doyle ?   ENTY\n",
              "2     How can I find a list of celebrities ' real na...   DESC\n",
              "3     What fowl grabs the spotlight after the Chines...   ENTY\n",
              "4                       What is the full form of .com ?   ABBR\n",
              "...                                                 ...    ...\n",
              "5447            What 's the shape of a camel 's spine ?   ENTY\n",
              "5448           What type of currency is used in China ?   ENTY\n",
              "5449                    What is the temperature today ?    NUM\n",
              "5450              What is the temperature for cooking ?    NUM\n",
              "5451               What currency is used in Australia ?   ENTY\n",
              "\n",
              "[5452 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 261
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "LsS55kTOZc59",
        "outputId": "54aabf92-27f3-43a6-f60b-a2ec362895bd"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "labelencoder = LabelEncoder()\n",
        "df['Labels'] = labelencoder.fit_transform(df['Labels'])\n",
        "df\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How did serfdom develop in and then leave Russ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What films featured the character Popeye Doyle ?</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>How can I find a list of celebrities ' real na...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What fowl grabs the spotlight after the Chines...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the full form of .com ?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5447</th>\n",
              "      <td>What 's the shape of a camel 's spine ?</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>What type of currency is used in China ?</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5449</th>\n",
              "      <td>What is the temperature today ?</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5450</th>\n",
              "      <td>What is the temperature for cooking ?</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5451</th>\n",
              "      <td>What currency is used in Australia ?</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5452 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Text  Labels\n",
              "0     How did serfdom develop in and then leave Russ...       1\n",
              "1      What films featured the character Popeye Doyle ?       2\n",
              "2     How can I find a list of celebrities ' real na...       1\n",
              "3     What fowl grabs the spotlight after the Chines...       2\n",
              "4                       What is the full form of .com ?       0\n",
              "...                                                 ...     ...\n",
              "5447            What 's the shape of a camel 's spine ?       2\n",
              "5448           What type of currency is used in China ?       2\n",
              "5449                    What is the temperature today ?       5\n",
              "5450              What is the temperature for cooking ?       5\n",
              "5451               What currency is used in Australia ?       2\n",
              "\n",
              "[5452 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 262
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0zA84ErIIOb",
        "outputId": "96aaf87b-c9d5-43ec-baa2-75f2061a00ae"
      },
      "source": [
        "maxl = 0\n",
        "for i in df.iloc[:,0]:\n",
        "    if(len(i.split(\" \"))>maxl):\n",
        "        maxl = len(i.split(\" \"))\n",
        "print(maxl, \"<- Max length of sentence required for padding\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "37 <- Max length of sentence required for padding\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "ITLZBXN1aCRK",
        "outputId": "75e7a340-8225-4f52-f563-c1a6f576b4ae"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(df, test_size=0.2, shuffle=True)\n",
        "train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4974</th>\n",
              "      <td>Who wrote the bestselling Missionary Travels a...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>428</th>\n",
              "      <td>What is Jane Goodall known for ?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1800</th>\n",
              "      <td>What comedian was banned from the Ed Sullivan ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3828</th>\n",
              "      <td>What director portrayed the commandant of the ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4874</th>\n",
              "      <td>What common plant has a button , cap , cup , g...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4533</th>\n",
              "      <td>When did the last Americans leave Vietnam ?</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1723</th>\n",
              "      <td>Where is Santa Lucia ?</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>736</th>\n",
              "      <td>What facial feature typically contains about 5...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5442</th>\n",
              "      <td>What is the meaning of caliente , in English , ?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2159</th>\n",
              "      <td>What is a heuristic ?</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4361 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Text  Labels\n",
              "4974  Who wrote the bestselling Missionary Travels a...       3\n",
              "428                    What is Jane Goodall known for ?       1\n",
              "1800  What comedian was banned from the Ed Sullivan ...       3\n",
              "3828  What director portrayed the commandant of the ...       3\n",
              "4874  What common plant has a button , cap , cup , g...       2\n",
              "...                                                 ...     ...\n",
              "4533        When did the last Americans leave Vietnam ?       5\n",
              "1723                             Where is Santa Lucia ?       4\n",
              "736   What facial feature typically contains about 5...       1\n",
              "5442   What is the meaning of caliente , in English , ?       1\n",
              "2159                              What is a heuristic ?       1\n",
              "\n",
              "[4361 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 424
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kktmjc46bgwG"
      },
      "source": [
        "train.to_csv(\"train.csv\", index=False)\n",
        "test.to_csv(\"test.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtpG4GnpaRGH",
        "outputId": "3564c690-fb14-409d-fec4-650115363f17"
      },
      "source": [
        "import spacy\n",
        "spacy_en = spacy.load('en')\n",
        "is_cuda = torch.cuda.is_available()\n",
        "print(\"Cuda Status on system is {}\".format(is_cuda))\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda Status on system is True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9N4s5ciaRWd"
      },
      "source": [
        "TEXT = data.Field(sequential=True, tokenize=\"spacy\", fix_length=38)\n",
        "LABEL = data.LabelField(dtype=torch.long, sequential=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NQHdjTbaRZT"
      },
      "source": [
        "train_data, _, test_data = data.TabularDataset.splits(\n",
        "    path=\"/content/\", train=\"train.csv\", validation=\"test.csv\", test=\"test.csv\",format=\"csv\", skip_header=True, \n",
        "    fields=[('Text', TEXT), ('Label', LABEL)]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTtlBX7naRcv",
        "outputId": "65365bf7-c920-4034-c13a-c4f37c418df0"
      },
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 4361\n",
            "Number of testing examples: 1091\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iB24uMRHb3fG"
      },
      "source": [
        "TEXT.build_vocab(train_data, vectors='glove.twitter.27B.50d', \n",
        "                 max_size=20000, min_freq=1)\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-UE_Tlsb3kv",
        "outputId": "19af79f1-8f17-47ad-a880-8cb69c3f5409"
      },
      "source": [
        "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in TEXT vocabulary: 8175\n",
            "Unique tokens in LABEL vocabulary: 6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_uIsntUoqs4",
        "outputId": "54dcbbd1-8f29-4a94-a4bf-c869b8e19081"
      },
      "source": [
        "LABEL.vocab.freqs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'0': 74, '1': 927, '2': 992, '3': 995, '4': 659, '5': 714})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 459
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECqefcYUb3nx"
      },
      "source": [
        "BATCH_SIZE = 20\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# keep in mind the sort_key option \n",
        "train_iterator, _, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, _, test_data), sort_key=lambda x: len(x.Text),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uEWv-y3ND67",
        "outputId": "174c9594-1f26-470e-92ab-0d93d5e8ac0b"
      },
      "source": [
        "TEXT.vocab.vectors.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8175, 50])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 461
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dyd1WJ-3b3rM"
      },
      "source": [
        "class TextCNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, input_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.conv1d_4 = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=embedding_dim, out_channels=2, kernel_size=4),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.MaxPool1d(kernel_size=(input_size-4+1))\n",
        "        )\n",
        "        self.conv1d_3 = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=embedding_dim, out_channels=2, kernel_size=3),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.MaxPool1d(kernel_size=(input_size-3+1))\n",
        "        )\n",
        "        self.conv1d_2 = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=embedding_dim, out_channels=2, kernel_size=2),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.MaxPool1d(kernel_size=(input_size-2+1))\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        # embedded shape -> [sent_len, batch_size, emb_dim]\n",
        "        embedded = embedded.permute(1,2,0)\n",
        "        # embedded shape -> [batch_size, emb_dim, sent_len]\n",
        "        out_conv_4 = self.conv1d_4(embedded)\n",
        "        out_conv_3 = self.conv1d_3(embedded)\n",
        "        out_conv_2 = self.conv1d_2(embedded)\n",
        "        out_combined = torch.cat([out_conv_4,out_conv_3,out_conv_2],1)\n",
        "        #print(out_conv_4.shape, out_conv_3.shape, out_combined.shape)\n",
        "        return out_combined"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zupPc__EiZHQ"
      },
      "source": [
        "class TextCNN_Avg(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, input_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.conv1d_4 = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=embedding_dim, out_channels=2, kernel_size=4),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.AvgPool1d(kernel_size=(input_size-4+1))\n",
        "        )\n",
        "        self.conv1d_3 = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=embedding_dim, out_channels=2, kernel_size=3),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.AvgPool1d(kernel_size=(input_size-3+1))\n",
        "        )\n",
        "        self.conv1d_2 = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=embedding_dim, out_channels=2, kernel_size=2),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.AvgPool1d(kernel_size=(input_size-2+1))\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        # embedded shape -> [sent_len, batch_size, emb_dim]\n",
        "        embedded = embedded.permute(1,2,0)\n",
        "        # embedded shape -> [batch_size, emb_dim, sent_len]\n",
        "        out_conv_4 = self.conv1d_4(embedded)\n",
        "        out_conv_3 = self.conv1d_3(embedded)\n",
        "        out_conv_2 = self.conv1d_2(embedded)\n",
        "        out_combined = torch.cat([out_conv_4,out_conv_3,out_conv_2],1)\n",
        "        #print(out_conv_4.shape, out_conv_3.shape)\n",
        "        return out_combined"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIUHcdnMp966"
      },
      "source": [
        "class TextCNN_KMax(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, input_size, k):\n",
        "        super().__init__()\n",
        "\n",
        "        self.k = k\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.conv1d_4 = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=embedding_dim, out_channels=2, kernel_size=4),\n",
        "            nn.LeakyReLU(),\n",
        "        )\n",
        "        self.conv1d_3 = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=embedding_dim, out_channels=2, kernel_size=3),\n",
        "            nn.LeakyReLU(),\n",
        "        )\n",
        "        self.conv1d_2 = nn.Sequential(\n",
        "            nn.Conv1d(in_channels=embedding_dim, out_channels=2, kernel_size=2),\n",
        "            nn.LeakyReLU(),\n",
        "        )\n",
        "        self.fc = nn.Linear(6*self.k, 6)\n",
        "\n",
        "    def kmax_pooling(self, x, dim, k):\n",
        "        index = x.topk(k, dim = dim)[1].sort(dim = dim)[0]\n",
        "        return x.gather(dim, index)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        # embedded shape -> [sent_len, batch_size, emb_dim]\n",
        "        embedded = embedded.permute(1,2,0)\n",
        "        # embedded shape -> [batch_size, emb_dim, sent_len]\n",
        "        #print(embedded.shape)\n",
        "        out_conv_4 = self.conv1d_4(embedded)\n",
        "        out_k_4 = self.kmax_pooling(out_conv_4, 2, self.k)\n",
        "        out_conv_3 = self.conv1d_3(embedded)\n",
        "        out_k_3 = self.kmax_pooling(out_conv_3, 2, self.k)\n",
        "        out_conv_2 = self.conv1d_2(embedded)\n",
        "        out_k_2 = self.kmax_pooling(out_conv_2, 2, self.k)\n",
        "        combined = torch.cat([out_k_4,out_k_3,out_k_2],1)\n",
        "        combined = combined.view(-1,6*self.k)\n",
        "        #print(combined.shape)\n",
        "        combined = self.fc(combined)\n",
        "        #print(combined.shape)\n",
        "        out_combined = combined.view(-1,6,1)\n",
        "        #print(out_conv_4.shape, out_conv_3.shape, out_k_4.shape, out_k_3.shape, combined.shape)\n",
        "        return out_combined"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OnOLtaSBytM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e1df210-ba75-4320-ff98-e1445d01fb2f"
      },
      "source": [
        "model = TextCNN_KMax(VOCAB_SIZE, EMB_DIM, INPUT_DIM, 5)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TextCNN_KMax(\n",
            "  (embedding): Embedding(8175, 50)\n",
            "  (conv1d_4): Sequential(\n",
            "    (0): Conv1d(50, 2, kernel_size=(4,), stride=(1,))\n",
            "    (1): LeakyReLU(negative_slope=0.01)\n",
            "  )\n",
            "  (conv1d_3): Sequential(\n",
            "    (0): Conv1d(50, 2, kernel_size=(3,), stride=(1,))\n",
            "    (1): LeakyReLU(negative_slope=0.01)\n",
            "  )\n",
            "  (conv1d_2): Sequential(\n",
            "    (0): Conv1d(50, 2, kernel_size=(2,), stride=(1,))\n",
            "    (1): LeakyReLU(negative_slope=0.01)\n",
            "  )\n",
            "  (fc): Linear(in_features=30, out_features=6, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9iLc_D-C3w7"
      },
      "source": [
        "def predict_proba(preds):\n",
        "    softmax = nn.Softmax(dim=1)\n",
        "    preds= softmax(preds).squeeze(2)\n",
        "    return preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2zhCkftP1zl"
      },
      "source": [
        "def predict(preds):\n",
        "    softmax = nn.Softmax(dim=1)\n",
        "    preds, ind= torch.max(softmax(preds), 1)\n",
        "    return ind"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5PqAPSY3qog"
      },
      "source": [
        "def multi_class_accuracy(preds, y):\n",
        "    y = y.view(len(y),1)\n",
        "    #print(preds.shape, pred.shape, y.shape, \"acc\")\n",
        "    softmax = nn.Softmax(dim=1)\n",
        "    preds, ind= torch.max(softmax(preds), 1)\n",
        "    correct = (ind == y).float()\n",
        "    acc = correct.sum()/float(len(correct))\n",
        "    #print(acc.item(), \"ACCURACY\")\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rsguw97T0o_p"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.train()\n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(batch.Text)\n",
        "        #print(predictions.shape, batch.Label.view(len(batch.Label),1).shape, batch.Label.view(len(batch.Label),1), \"yoyo\")\n",
        "        loss = criterion(predictions, batch.Label.view(len(batch.Label),1))\n",
        "        acc = multi_class_accuracy(predictions, batch.Label.view(len(batch.Label),1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        #print((epoch_loss / len(iterator)),(epoch_acc / len(iterator)))\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwyPuoMN0pCS"
      },
      "source": [
        "def evaluate(model, iterator, criterion, make_roc_cm):\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            predictions = model(batch.Text)  \n",
        "            loss = criterion(predictions, batch.Label.view(len(batch.Label),1))\n",
        "            if make_roc_cm:\n",
        "                probs = predict_proba(predictions) \n",
        "                pred_lbls = predict(predictions)\n",
        "                for pred_lbl in pred_lbls.detach().cpu().numpy():\n",
        "                    global_preds_x.append(list(pred_lbl)[0])\n",
        "                for prob in probs.detach().cpu().numpy():\n",
        "                    global_roc_x.append(list(prob))\n",
        "                for lbl in batch.Label.view(len(batch.Label),1).detach().cpu().numpy():\n",
        "                    global_roc_y.append(list(lbl)[0])\n",
        "                \n",
        "            acc = multi_class_accuracy(predictions, batch.Label.view(len(batch.Label),1))\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slGJ4zxjk9XG"
      },
      "source": [
        "EMB_DIM = 50\n",
        "INPUT_DIM = 38\n",
        "VOCAB_SIZE = len(TEXT.vocab)\n",
        "model = TextCNN_KMax(VOCAB_SIZE, EMB_DIM, INPUT_DIM, 5)\n",
        "model.embedding.weight.data = TEXT.vocab.vectors.to(device)\n",
        "model = model.to(device)\n",
        "global_roc_x = []\n",
        "global_roc_y = []\n",
        "global_preds_x = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVnfTItVk9ap",
        "outputId": "96eb5608-6f3f-4c0c-a63f-cd8d61af7dad"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TextCNN(\n",
            "  (embedding): Embedding(8175, 50)\n",
            "  (conv1d_4): Sequential(\n",
            "    (0): Conv1d(50, 2, kernel_size=(4,), stride=(1,))\n",
            "    (1): LeakyReLU(negative_slope=0.01)\n",
            "    (2): MaxPool1d(kernel_size=35, stride=35, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv1d_3): Sequential(\n",
            "    (0): Conv1d(50, 2, kernel_size=(3,), stride=(1,))\n",
            "    (1): LeakyReLU(negative_slope=0.01)\n",
            "    (2): MaxPool1d(kernel_size=36, stride=36, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv1d_2): Sequential(\n",
            "    (0): Conv1d(50, 2, kernel_size=(2,), stride=(1,))\n",
            "    (1): LeakyReLU(negative_slope=0.01)\n",
            "    (2): MaxPool1d(kernel_size=37, stride=37, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTsydc3upvGZ"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmQyzX-48--p",
        "outputId": "74d65d57-cdb3-4e9b-9588-3c27e8f97fe8"
      },
      "source": [
        "for ep in range(50):\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    test_loss, test_acc = evaluate(model, test_iterator, criterion, False)\n",
        "    print(\"[Training Accuracy, Training Loss] ->\", train_acc,train_loss,\"[Test Accuracy, Test Loss] ->\",test_acc, test_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Training Accuracy, Training Loss] -> 0.3938356239569786 1.5391814643389559 [Test Accuracy, Test Loss] -> 0.5359504201195456 1.3137830582532015\n",
            "[Training Accuracy, Training Loss] -> 0.6673516081348402 1.0575605323325554 [Test Accuracy, Test Loss] -> 0.7139669580893083 0.8781905748627402\n",
            "[Training Accuracy, Training Loss] -> 0.7737443049748739 0.7133768660837112 [Test Accuracy, Test Loss] -> 0.7823140642859719 0.6834989748217842\n",
            "[Training Accuracy, Training Loss] -> 0.8271689619103523 0.5540992109334633 [Test Accuracy, Test Loss] -> 0.8023140614682978 0.6043212066997181\n",
            "[Training Accuracy, Training Loss] -> 0.8666666819624704 0.45328444567377163 [Test Accuracy, Test Loss] -> 0.8168595162304965 0.557500567219474\n",
            "[Training Accuracy, Training Loss] -> 0.8924657669785905 0.37896816907918346 [Test Accuracy, Test Loss] -> 0.8204958807338368 0.5304482809521935\n",
            "[Training Accuracy, Training Loss] -> 0.9178082287039386 0.3109797736008962 [Test Accuracy, Test Loss] -> 0.8323140621185303 0.4935558010231365\n",
            "[Training Accuracy, Training Loss] -> 0.9353881339504294 0.2555261609063709 [Test Accuracy, Test Loss] -> 0.8350413354960355 0.47739156674255023\n",
            "[Training Accuracy, Training Loss] -> 0.9456621062810018 0.21480664918592549 [Test Accuracy, Test Loss] -> 0.8386776989156549 0.466137772527608\n",
            "[Training Accuracy, Training Loss] -> 0.9557077653331844 0.1819089090528145 [Test Accuracy, Test Loss] -> 0.8386776967482134 0.4628726913170381\n",
            "[Training Accuracy, Training Loss] -> 0.9627853904140594 0.15569975644724282 [Test Accuracy, Test Loss] -> 0.8414049701257186 0.4571603246710517\n",
            "[Training Accuracy, Training Loss] -> 0.9698630144062652 0.13313701081187485 [Test Accuracy, Test Loss] -> 0.8350413376634771 0.454644324156371\n",
            "[Training Accuracy, Training Loss] -> 0.9748858447488584 0.11522945750623806 [Test Accuracy, Test Loss] -> 0.8368595188314264 0.4574220218441703\n",
            "[Training Accuracy, Training Loss] -> 0.9787671220357015 0.10061206587815666 [Test Accuracy, Test Loss] -> 0.8395867932926525 0.4557947364720431\n",
            "[Training Accuracy, Training Loss] -> 0.983105022341149 0.08839189880166083 [Test Accuracy, Test Loss] -> 0.8423140655864368 0.45649064711549064\n",
            "[Training Accuracy, Training Loss] -> 0.9867579882547736 0.07798484225476215 [Test Accuracy, Test Loss] -> 0.841404973376881 0.46382151462815024\n",
            "[Training Accuracy, Training Loss] -> 0.9874429201970906 0.06946562865070444 [Test Accuracy, Test Loss] -> 0.8432231556285511 0.4653806713494388\n",
            "[Training Accuracy, Training Loss] -> 0.9883561626961243 0.06276146610390786 [Test Accuracy, Test Loss] -> 0.8386777010830966 0.4704676870595325\n",
            "[Training Accuracy, Training Loss] -> 0.9904109571622387 0.05629467419678235 [Test Accuracy, Test Loss] -> 0.841404973376881 0.4784626689824191\n",
            "[Training Accuracy, Training Loss] -> 0.9906392679911226 0.051753034942770657 [Test Accuracy, Test Loss] -> 0.8395867922089316 0.4801741773431951\n",
            "[Training Accuracy, Training Loss] -> 0.991324199389105 0.04759528296087979 [Test Accuracy, Test Loss] -> 0.8350413376634771 0.4846790772947398\n",
            "[Training Accuracy, Training Loss] -> 0.9922374416159713 0.04377111427690068 [Test Accuracy, Test Loss] -> 0.8314049753275785 0.4940482818267562\n",
            "[Training Accuracy, Training Loss] -> 0.9929223735582883 0.04060001226916025 [Test Accuracy, Test Loss] -> 0.8304958852854643 0.4997914831069383\n",
            "[Training Accuracy, Training Loss] -> 0.9931506835706702 0.03740997116435447 [Test Accuracy, Test Loss] -> 0.835950429873033 0.5035937165672129\n",
            "[Training Accuracy, Training Loss] -> 0.9940639260697038 0.03486318263132497 [Test Accuracy, Test Loss] -> 0.8350413387471979 0.5108216740868309\n",
            "[Training Accuracy, Training Loss] -> 0.9945205469109696 0.0330877551558049 [Test Accuracy, Test Loss] -> 0.8268595196984031 0.5302394386719573\n",
            "[Training Accuracy, Training Loss] -> 0.9940639257975364 0.031002806873830484 [Test Accuracy, Test Loss] -> 0.8304958852854643 0.529067884656516\n",
            "[Training Accuracy, Training Loss] -> 0.9947488571955189 0.029316723337075374 [Test Accuracy, Test Loss] -> 0.8314049753275785 0.5340108360756527\n",
            "[Training Accuracy, Training Loss] -> 0.9949771682965701 0.02799039423204193 [Test Accuracy, Test Loss] -> 0.8341322487050836 0.5405398433858698\n",
            "[Training Accuracy, Training Loss] -> 0.9947488571955189 0.026533920699228174 [Test Accuracy, Test Loss] -> 0.8368595199151473 0.5460386010733518\n",
            "[Training Accuracy, Training Loss] -> 0.9956620996945524 0.02541454827943078 [Test Accuracy, Test Loss] -> 0.8304958852854643 0.5592323977161537\n",
            "[Training Accuracy, Training Loss] -> 0.995890410251269 0.024860060936983962 [Test Accuracy, Test Loss] -> 0.8368595199151473 0.5645596206188201\n",
            "[Training Accuracy, Training Loss] -> 0.995890410251269 0.023720437538550666 [Test Accuracy, Test Loss] -> 0.8341322465376421 0.5713456267660314\n",
            "[Training Accuracy, Training Loss] -> 0.9954337894100033 0.023274148039872752 [Test Accuracy, Test Loss] -> 0.835950429873033 0.577770484983921\n",
            "[Training Accuracy, Training Loss] -> 0.9952054785811193 0.02220292897766337 [Test Accuracy, Test Loss] -> 0.8368595199151473 0.5857809670946815\n",
            "[Training Accuracy, Training Loss] -> 0.9956620994223851 0.021845369915781992 [Test Accuracy, Test Loss] -> 0.8368595199151473 0.5924695434895428\n",
            "[Training Accuracy, Training Loss] -> 0.995890410251269 0.021227356938955683 [Test Accuracy, Test Loss] -> 0.8368595209988681 0.6003170778805559\n",
            "[Training Accuracy, Training Loss] -> 0.995890410251269 0.020824645937486345 [Test Accuracy, Test Loss] -> 0.835950429873033 0.6101660358634862\n",
            "[Training Accuracy, Training Loss] -> 0.9958904099791017 0.020689161307518796 [Test Accuracy, Test Loss] -> 0.8359504287893121 0.6148400538346984\n",
            "[Training Accuracy, Training Loss] -> 0.9956620994223851 0.019852101527336245 [Test Accuracy, Test Loss] -> 0.8377686121247031 0.6243082622912797\n",
            "[Training Accuracy, Training Loss] -> 0.9956620994223851 0.01991603044276317 [Test Accuracy, Test Loss] -> 0.8368595209988681 0.6279288957064803\n",
            "[Training Accuracy, Training Loss] -> 0.9956620994223851 0.019165499338980648 [Test Accuracy, Test Loss] -> 0.8350413409146396 0.6407971313053912\n",
            "[Training Accuracy, Training Loss] -> 0.995890410251269 0.01900803934062191 [Test Accuracy, Test Loss] -> 0.8314049774950201 0.648112437399951\n",
            "[Training Accuracy, Training Loss] -> 0.9956620996945524 0.01911636878078225 [Test Accuracy, Test Loss] -> 0.8314049785787408 0.6580014097419652\n",
            "[Training Accuracy, Training Loss] -> 0.9956620996945524 0.0193808025240071 [Test Accuracy, Test Loss] -> 0.8314049764112993 0.6641503059051254\n",
            "[Training Accuracy, Training Loss] -> 0.995890410251269 0.017824217646351385 [Test Accuracy, Test Loss] -> 0.8241322506557811 0.6749238585883921\n",
            "[Training Accuracy, Training Loss] -> 0.9954337894100033 0.01860726462702066 [Test Accuracy, Test Loss] -> 0.8286777052012357 0.6771750252355229\n",
            "[Training Accuracy, Training Loss] -> 0.9956620994223851 0.017819712033851996 [Test Accuracy, Test Loss] -> 0.8304958885366266 0.6823546122420918\n",
            "[Training Accuracy, Training Loss] -> 0.9956621002388871 0.01741620979086309 [Test Accuracy, Test Loss] -> 0.8286777041175148 0.6920320651747963\n",
            "[Training Accuracy, Training Loss] -> 0.9956620994223851 0.01672557280240761 [Test Accuracy, Test Loss] -> 0.8277686129916798 0.700665790384466\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EE8gh8X7mstO",
        "outputId": "e7cd5e09-d049-4062-aaed-a237a749be92"
      },
      "source": [
        "print(global_roc_x, global_roc_y, global_preds_x)\n",
        "print(global_roc_x.copy(), global_roc_y.copy(), global_preds_x.copy())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[] [] []\n",
            "[] [] []\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zp344Xj-aOSL",
        "outputId": "63c1cf23-bec6-4e16-9a95-27dfc9cd5217"
      },
      "source": [
        "test_loss, test_acc = evaluate(model, test_iterator, criterion, True)\n",
        "print(test_loss, test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7006657879460941 0.8277686129916798\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQHfVMoYJ06C"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "onehot_encoded_y = onehot_encoder.fit_transform(np.array(global_roc_y).reshape(-1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hid9EPR7OCWj",
        "outputId": "21458a01-80a9-4800-b633-5a1ca9dd4f04"
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, multilabel_confusion_matrix\n",
        "from sklearn.metrics import f1_score\n",
        "!matplotlib inline\n",
        "\n",
        "def plot_roc(y_probs, y_test, plot_name):\n",
        "    y_probs = np.array(y_probs)\n",
        "    for i in range(6):\n",
        "        lr_fpr, lr_tpr, _ = roc_curve(y_test[:,i],y_probs[:,i])\n",
        "        plt.plot(lr_fpr, lr_tpr, marker='.', label='Number-'+str(i))\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.legend()\n",
        "    #plt.show()\n",
        "    plt.savefig(plot_name+\".png\")\n",
        "    plt.close()\n",
        "\n",
        "def plot_confusion_matrix(y_pred, y_test, plot_name):\n",
        "    y_test = np.array(y_test).reshape(-1,1)\n",
        "    y_pred = np.array(y_pred).reshape(-1,1)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print(cm)\n",
        "    cmd = ConfusionMatrixDisplay(cm, display_labels=['0','1','2','3','4','5','6','7','8','9'])\n",
        "    cmd.plot()\n",
        "    #plt.show()\n",
        "    plt.savefig(plot_name+\".png\")\n",
        "    plt.close()\n",
        "\n",
        "def get_f1_score(y_pred, y_test):\n",
        "    y_test = np.array(y_test).reshape(-1,1)\n",
        "    y_pred = np.array(y_pred).reshape(-1,1)\n",
        "    print(f1_score(y_test, y_pred, average = None))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: matplotlib: command not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmt6Owg7Oxqn"
      },
      "source": [
        "plot_roc(global_roc_x.copy(), onehot_encoded_y.copy(), \"ROC_twitter50_Model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkaAj9z1SIuj",
        "outputId": "31c4b4df-c0e8-4fa3-8e40-f8b898280e1e"
      },
      "source": [
        "plot_confusion_matrix(global_preds_x.copy(), global_roc_y.copy(),\"CF_twitter50_Model\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[190  28   5   2   3   0]\n",
            " [ 23 179  44   4   8   0]\n",
            " [  6  19 197   4   6   3]\n",
            " [  1   4   5 171   1   0]\n",
            " [  2   9   2   3 160   0]\n",
            " [  0   0   4   1   0   7]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUsrLwWVPc9E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0057232-b36a-40d9-ba4f-ed005d4d5db6"
      },
      "source": [
        "get_f1_score(global_preds_x.copy(), global_roc_y.copy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.84444444 0.72032193 0.80081301 0.93188011 0.9039548  0.63636364]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyZoy760sqUR"
      },
      "source": [
        "import dill\n",
        "with open('best_model_3b.pkl', 'wb') as f:\n",
        "    dill.dump(model, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxB19kKkOolr"
      },
      "source": [
        "# **FIN**\n"
      ]
    }
  ]
}